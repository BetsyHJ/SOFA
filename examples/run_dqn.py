import sys
sys.path.append('../src/')
import os
os.environ['KMP_DUPLICATE_LIB_OK']='True'

import numpy as np
from time import time, localtime, strftime
import configparser

# from env.env import SOFAEnv, simulated_data
from env.env_multiusers import SOFAEnv, simulated_data

from train import train
from evaluation import evaluate, eval_yahoo_sinTurn, yahoo_eval_1, yahoo_eval_1_calu_itemset

# np.random.seed(2020)

def _get_conf(conf_name):
    config = configparser.ConfigParser()
    config.read("../conf/"+conf_name+".properties")
    conf=dict(config.items("default"))

    np.random.seed(int(conf['seed']))
    # # for multiple jobs in 
    # args = set_hparams()
    # conf["data.debiasing"] = args.debiasing
    # conf["seed"] = str(args.seed)

    evalProcess = conf['evaluation']
    if evalProcess.lower() == 'false':
        if ((conf["data.input.dataset"] == 'sim4') or (conf["data.input.dataset"] == 'sim5')) and (conf["data.debiasing"] == 'GT'):
            rating_file = conf["data.input.path"] + conf["data.input.dataset"] + "_GT_ratingM.ascii"
        else:
            rating_file = conf["data.input.path"] + conf["data.input.dataset"] + '_' + \
            conf["data.gen_model"] + '_' + conf["data.debiasing"] + "_ratingM.ascii"
            if conf["data.debiasing"] == 'GT':
                rating_file = conf["data.input.path"] + conf["data.input.dataset"] + "_pseudoGT_ratingM.ascii"
                print("we use a pseudo GT for yahoo, which is generated by MF on unbiased testset:", rating_file)
    else:
        if conf["data.input.dataset"].lower() == "sim4" or conf["data.input.dataset"].lower() == "sim5":
            print('now evaluation process only for simulated dataset which has the groundTruth')
            rating_file = conf["data.input.path"] + conf["data.input.dataset"] + "_GT_ratingM.ascii"
            # rating_file = conf["data.input.path"] + conf["data.input.dataset"] + '_' + \
            # conf["data.gen_model"] + '_' + conf["data.debiasing"] + "_ratingM.ascii"
        elif conf["data.input.dataset"].lower() in ["yahoo", "coat"]:
            rating_file = conf["data.input.path"] + conf["data.input.dataset"] + '_' + \
            conf["data.gen_model"] + '_' + conf["data.debiasing"] + "_ratingM.ascii" # this simulator is not for evaluation directly, but for several interaction to generate states
            # solution-2 with pseudo GT
            rating_file = conf["data.input.path"] + conf["data.input.dataset"] + "_pseudoGT_ratingM.ascii"
            print("we use a pseudo GT for yahoo, which is generated by MF on unbiased testset:", rating_file)
        else:
            print("check data")
    conf["RATING_TYPE"] = conf["rating_type"]
    # # conf['RATINGS'] = np.clip(np.loadtxt(rating_file), 1.0, 5.0)
    # # print("rating of simulator is float")
    # if evalProcess.lower() == 'true':
    #     ratingM = np.clip(np.round(np.loadtxt(rating_file)).astype('int'), 1, 5)
    #     if conf["data.input.dataset"].lower() == "sim5":
    #         trainM = np.loadtxt('../../../sigir2020/data/simulated5/train.ascii', dtype=int)
    #         conf['RATINGS'] = np.where(trainM>0, 1, ratingM)
    #     else:
    #         print("non for other dataset, only for sim5")
    #         exit(0)
    # else:
    #     conf["RATINGS"] = np.clip(np.round(np.loadtxt(rating_file)).astype('int'), 1, 5)
    conf["RATINGS"] = np.clip(np.round(np.loadtxt(rating_file)).astype('int'), 1, 5)
    # item_emb_file = conf["data.input.path"] + conf["data.input.dataset"] + '_' + \
    #     conf["data.gen_model"] + '_' + conf["data.debiasing"] + "_item.emb"
    # conf["ITEM_VEC"] = np.loadtxt(item_emb_file)
    # print(conf["ITEM_VEC"].shape, item_emb_file)
    conf["EPISODE_LENGTH"] = conf["episode_length"]
    conf['mode'] = conf['mode'].upper()
    if conf['mode'] == 'DOUBLEDQN':
        conf['mode'] = 'DoubleDQN'
    return conf

def _logging_(basis_conf, params_conf):
    now = localtime(time())
    now = strftime("%Y-%m-%d %H:%M:%S", now)
    origin_data_name = basis_conf["data.input.dataset"]
    gen_model = basis_conf["data.gen_model"]
    debiasing = basis_conf["data.debiasing"]
    print(now + " - data:%s" % origin_data_name)
    print(now + " - gen_model:%s, debiasing:%s" % (gen_model, debiasing))
    print(now + " - RL Algo: %s, state_encoder: %s" % (basis_conf['mode'], params_conf['state_encoder']))
    print("conf : " + str(params_conf), flush=True)


def run_dqn():
    conf = _get_conf('yahoo')
    # conf['RATINGS'], item_vec = simulated_data(10, 20)

    # item_vec = conf["ITEM_VEC"]
    sofa = SOFAEnv(conf)
    action_space = sofa.num_items
    num_users = sofa.num_users

    # init DQN
    config = load_parameters(conf['mode'])
    config['STATE_MAXLENGTH'] = int(conf["episode_length"])
    config['ACTION_SPACE'] = action_space

    # tuning = 'learning_rate'.upper()
    # tuning = 'memory_size'.upper()
    # tuning = 'batch_size'.upper()
    # tuning = 'gamma'.upper()
    # tuning = 'optimizer'.upper()
    # tuning = 'replace_targetnet'.upper()
    # tuning = 'epsilon_decay_step'
    # tuning = 'lr_decay_step'
    # tuning = "state_encoder"
    # tuning = 'action_dim'.upper()
    # tuning = 'RNN_STATE_DIM'
    # print("tuning:",tuning)
    config['SAVE_MODEL_FILE'] = conf["data.input.dataset"] + '_' + \
        conf["data.gen_model"] + '_' + conf["data.debiasing"] + '_' + \
        conf['mode'] + '_' + config["state_encoder"] + '_' + 'r-12_SmoothL1_' + 'nohuman_' + "seed" + conf["seed"] + '_'#+ tuning + str(config[tuning]) + '_' \
        #+ "actiondim500_" #"rnn_state_10_"
        # 'episode20_' or 'nohuman_' or 'trick1_' 'r-12_SmoothL1_'
        #+ "seed" + conf["seed"] + '_'
    # if conf["data.input.dataset"].lower() == 'yahoo':
    #     config['SAVE_MODEL_FILE'] += 'le-1_'
        # 'testuser_'
    # config['SAVE_MODEL_FILE'] = 'sim_random_' + str(num_users) + '_' + str(action_space) + '_' + config["state_encoder"] + '_'

    _logging_(conf, config)
    # config['ACTION_DIM'] = item_vec.shape[1]
    # config['ACTION_FEATURE'] = item_vec

    ## train process
    evalProcess = conf['evaluation']
    if evalProcess.lower() == 'false':
        train(conf, config, sofa)
    else:
        if conf["data.input.dataset"].lower() in ['yahoo', 'coat']:
            test_file = conf["data.input.path"] + conf["data.input.dataset"] + "_test.ascii"
            # eval_yahoo_sinTurn(conf, config, sofa, test_file)
            yahoo_eval_1(conf, config, sofa, test_file)
            # yahoo_eval_1_calu_itemset(conf, config, sofa, test_file)
            # # solution-2 with a pseudo GT
            # evaluate(conf, config, sofa, test_file)
        else:
            evaluate(conf, config, sofa)


def load_parameters(mode):
    # config = dict()
    # # config['STATE_MAXLENGTH'] = 10 # also be the length of episode
    # config['ACTION_DIM'] = 10
    # config['RNN_STATE_DIM'] = 10
    # config['MEMORY_SIZE'] = 20000
    # config['GAMMA'] = 0.9 # reward decay
    # # config['GAMMA'] = 0.4 # 0.4 ** 3 = 0.064, see 2-3 steps
    # config['LEARNING_RATE'] = 1e-4 # 1e-4 before
    # config['EPSILON'] = 0.75
    # config['BATCH_SIZE'] = 512 # before it is 256
    # config['REPLACE_TARGETNET'] = 100

    ## load from configfile
    params = {}
    config = configparser.ConfigParser()
    config.read("../conf/"+mode+".properties")
    conf=dict(config.items("hyperparameters"))
    params['ACTION_DIM'] = int(conf['action_dim'])
    params['MEMORY_SIZE'] = int(conf['memory_size'])
    params['GAMMA'] = float(conf['gamma']) # reward decay
    params['LEARNING_RATE'] = float(conf['learning_rate'])
    params['EPSILON'] = float(conf['epsilon'])
    params['BATCH_SIZE'] = int(conf['batch_size'])
    params['REPLACE_TARGETNET'] = int(conf['replace_targetnet'])
    params['OPTIMIZER'] = conf['optimizer']
    params['RNN_STATE_DIM'] = int(conf['rnn_state_dim'])
    params['state_encoder'] = conf['state_encoder']
    params['lr_decay_step'] = conf['lr_decay_step']
    params['epsilon_decay_step'] = conf['epsilon_decay_step']
    return params
    
def set_hparams():
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument('--seed', type=int)
    parser.add_argument('--debiasing', type=str)
    args = parser.parse_args()
    print("now the seed is", args.seed, flush=True)
    np.random.seed(args.seed)
    return args

if __name__ == "__main__":
    run_dqn()
    print("End. " + strftime("%Y-%m-%d %H:%M:%S", localtime(time())))
# print("checkpoint")